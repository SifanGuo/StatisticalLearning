{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 1\n",
    "#### Question 1.(a) Explain how k-fold cross-validation is implemented\n",
    "\n",
    "    1. We randomly divide the set of observations into k groups of approximately equal size.\n",
    "    \n",
    "    2. We'll train the model for k times. Every time we select one group as our validation set and the other k-1 groups as our training sets.\n",
    "    \n",
    "    3. Then, we have k estimates of the test error.\n",
    "    \n",
    "    4. Finally, we average these values to get the k-fold CV estimate.\n",
    "\n",
    "#### Question 1.(b) What are the advantages and disadvantages of k-fold cross validation relative to\n",
    "    1. The validation set approach; \n",
    "    Advantage of k-fold CV: Because only a relatively smaller part of observations are used in the model training, the model might perform worse, which can result in the overestimation of the test error. Since the training-testing datasets are randomly divided, the validation estimate of the test error may be highly variable. \n",
    "    \n",
    "    Advantages of the validation set approach: The validation set approach is faster than k-fold CV for that we only need to fit the model once and calculate the error once.\n",
    "    \n",
    "    2. LOOCV\n",
    "    Advantages of k-fold CV: LOOCV requires fitting model n times, which can be computationally expensive, whereas k-fold CV can be applied to almost any models for its feasibility. Moreover, k-fold CV often gives more accurate estimates of the test error rate than LOOCV.\n",
    "    \n",
    "    Advantages of LOOCV:  Because of the bias-variance trade-off, LOOCV may give approximately unbiased (the result doesn't change too much) estimates of the test error, even though LOOCV has higher variance than k-fold CV.\n",
    "\n",
    "<font size=\"3\">\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <font size=\"3\"> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "redwine_df = pd.read_csv(\"redwine.csv\")\n",
    "\n",
    "redwine_df[\"final_quality\"] = 0\n",
    "\n",
    "redwine_df[\"final_quality\"][redwine_df[\"quality\"] > redwine_df[\"quality\"].mean()] = 1\n",
    "\n",
    "redwine_df[\"final_quality\"].head()\n",
    "\n",
    "X = redwine_df.iloc[:, :-2]\n",
    "y = redwine_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  \n",
       "0      9.4  \n",
       "1      9.8  \n",
       "2      9.8  \n",
       "3      9.8  \n",
       "4      9.4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: final_quality, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.(a) Fit a logistic regression model that uses all predictors (except quality) to predict final_quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit_model = LogisticRegression().fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2. (b)Using the validation set approach, estimate the test error of this model. In order to do this,\n",
    "you must perform the following steps:\n",
    "    i. Split the sample set into a training set and a validation set.\n",
    "    \n",
    "    ii. Fit a multiple logistic regression model using only the training observations.\n",
    "    \n",
    "    iii. Obtain a prediction of final_quality for each wine in the validation set by computing   \n",
    "    the posterior probability of high-quality for that wine, and classifying the wine to the\n",
    "    high-quality category if the posterior probability is greater than 0.5.\n",
    "    \n",
    "    iv. Compute the validation set error, which is the fraction of the observations in the\n",
    "    validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation set error is  0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# i. Split the sample set into a training set and a validation set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=666)\n",
    "\n",
    "# ii. Fit a multiple logistic regression model using only the training observations.\n",
    "logit_model = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# iii. Obtain a prediction of final_quality for each wine in the validation set.\n",
    "y_pred_prob = logit_model.predict_proba(X_test)\n",
    "# print(logit_model.classes_)\n",
    "# print(y_pred_prob.shape)\n",
    "y_pred_high_quality = y_pred_prob[:, 1]\n",
    "y_pred_high_quality[y_pred_high_quality > 0.50] = 1\n",
    "y_pred_high_quality[y_pred_high_quality < 0.50] = 0\n",
    "\n",
    "# print(len(y_pred_high_quality))\n",
    "\n",
    "# Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.\n",
    "print(\"The validation set error is \", accuracy_score(y_test, y_pred_high_quality))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 \n",
    "    a. Write a function, boot_fn(), that takes as input the redwine data set as well as an index of the\n",
    "    observations, and that outputs the coefficient estimates for each predictor in the multiple\n",
    "    logistic regression model.\n",
    "    \n",
    "    b. Use the boot() function together with your boot_fn() function to estimate the standard\n",
    "    errors of the logistic regression coefficients for each predictor.\n",
    "    \n",
    "    c. Comment on the estimated standard errors obtained using the glm() function and using your\n",
    "    bootstrap function. One way to get these values in python is use of statsmodel library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.517706\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>final_quality</td>  <th>  No. Observations:  </th>   <td>  1599</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  1587</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>    11</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 18 Mar 2019</td> <th>  Pseudo R-squ.:     </th>   <td>0.2505</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>18:44:26</td>     <th>  Log-Likelihood:    </th>  <td> -827.81</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1104.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.316e-111</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>   42.9499</td> <td>   79.476</td> <td>    0.540</td> <td> 0.589</td> <td> -112.820</td> <td>  198.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fixed acidity</th>        <td>    0.1360</td> <td>    0.098</td> <td>    1.381</td> <td> 0.167</td> <td>   -0.057</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -3.2817</td> <td>    0.488</td> <td>   -6.722</td> <td> 0.000</td> <td>   -4.239</td> <td>   -2.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>   -1.2743</td> <td>    0.563</td> <td>   -2.265</td> <td> 0.024</td> <td>   -2.377</td> <td>   -0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.0553</td> <td>    0.054</td> <td>    1.029</td> <td> 0.304</td> <td>   -0.050</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -3.9157</td> <td>    1.569</td> <td>   -2.495</td> <td> 0.013</td> <td>   -6.992</td> <td>   -0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0222</td> <td>    0.008</td> <td>    2.698</td> <td> 0.007</td> <td>    0.006</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0164</td> <td>    0.003</td> <td>   -5.688</td> <td> 0.000</td> <td>   -0.022</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td>  -50.9324</td> <td>   81.151</td> <td>   -0.628</td> <td> 0.530</td> <td> -209.985</td> <td>  108.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>   -0.3806</td> <td>    0.720</td> <td>   -0.528</td> <td> 0.597</td> <td>   -1.792</td> <td>    1.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    2.7951</td> <td>    0.452</td> <td>    6.181</td> <td> 0.000</td> <td>    1.909</td> <td>    3.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.8668</td> <td>    0.104</td> <td>    8.319</td> <td> 0.000</td> <td>    0.663</td> <td>    1.071</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:          final_quality   No. Observations:                 1599\n",
       "Model:                          Logit   Df Residuals:                     1587\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Mon, 18 Mar 2019   Pseudo R-squ.:                  0.2505\n",
       "Time:                        18:44:26   Log-Likelihood:                -827.81\n",
       "converged:                       True   LL-Null:                       -1104.5\n",
       "                                        LLR p-value:                1.316e-111\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                   42.9499     79.476      0.540      0.589    -112.820     198.720\n",
       "fixed acidity            0.1360      0.098      1.381      0.167      -0.057       0.329\n",
       "volatile acidity        -3.2817      0.488     -6.722      0.000      -4.239      -2.325\n",
       "citric acid             -1.2743      0.563     -2.265      0.024      -2.377      -0.171\n",
       "residual sugar           0.0553      0.054      1.029      0.304      -0.050       0.161\n",
       "chlorides               -3.9157      1.569     -2.495      0.013      -6.992      -0.840\n",
       "free sulfur dioxide      0.0222      0.008      2.698      0.007       0.006       0.038\n",
       "total sulfur dioxide    -0.0164      0.003     -5.688      0.000      -0.022      -0.011\n",
       "density                -50.9324     81.151     -0.628      0.530    -209.985     108.120\n",
       "pH                      -0.3806      0.720     -0.528      0.597      -1.792       1.031\n",
       "sulphates                2.7951      0.452      6.181      0.000       1.909       3.681\n",
       "alcohol                  0.8668      0.104      8.319      0.000       0.663       1.071\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_add_constant  = sm.add_constant(X)\n",
    "logit_model = sm.Logit(y, X_add_constant)\n",
    "result = logit_model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Logit' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-fdd62d9e1cd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGenericLikelihoodModelResults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mGenericLikelihoodModelResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mbootstrap\u001b[1;34m(self, nrep, method, disp, store)\u001b[0m\n\u001b[0;32m   2053\u001b[0m         \"\"\"\n\u001b[0;32m   2054\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2055\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2056\u001b[0m         \u001b[0mhascloneattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cloneattr'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2057\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Logit' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "from statsmodels.base.model import GenericLikelihoodModelResults\n",
    "\n",
    "GenericLikelihoodModelResults.bootstrap(logit_model, nrep=100, method='nm', disp=0, store=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
