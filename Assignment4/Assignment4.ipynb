{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 4\n",
    "### Question 1\n",
    "#### Read and summarize the subsection on \"Another Formulation for Ridge Regression and the Lasso\" (pp 220-222).\n",
    "\n",
    "<font size=2.5 color=\"red\">Answer: \n",
    "This subsection introduces a new formulation for lasso and ridge regression. Instead of using λ before the penalty terms $ \\sum_{j=1}^p |\\beta_j| $ or $ \\sum_{j=1}^p \\beta_j^2 $, this formulation uses s to minimize the penalty terms such that $ \\sum_{j=1}^p |\\beta_j| \\leq s $ or $ \\sum_{j=1}^p \\beta_j^2 \\leq s $, which tries to find the set of coefficient estimates with the smallest RSS. When s is very large, the coefficient estimates can be large, too. It's basically yielding the least squares solutions. On the other hand, the coefficient estimates would be very small when s is set small. \n",
    "\n",
    "Moreover, the subsection also mentions the connection between the lasso, ridge regression and the best subset selection. Ridge and lasso regression can be regarded as computationally feasible alternatives to best subset selection.\n",
    "\n",
    "Last but not least, \"The Variable Selection Property of the Lasso\" draws two figures showing the difference between lasso and ridge regression, which explains why lasso can result in zero coefficient estimates whereas ridge cannot. It's due to the shape of the constraint regions. The ridge regression has a circular constraint with no sharp points, the intersection with the RSS ellipse will not generally occur on an axis. In contrast, the lasso constraint has corners at each of the axes, and so the ellipse will often intersect the constraint region at an axis. That's how we get a zero coefficient.\n",
    "</font>\n",
    "\n",
    "\n",
    "\n",
    "### Question 2\n",
    "#### In this exercise, we will generate simulated data, then use this data to perform forward feature selection, backward feature selection and lasso.\n",
    "\n",
    "(a) Generate a predictor X of length n = 100, as well as a noise vector ϵ of length n = 100 from a\n",
    "random normal distribution. Then generate a response vector Y of length n = 100 according to the\n",
    "model Y = β0 + β1X + β2X2 + β3X3 + ϵ, where β0, β1, β2, and β3 are constants of your choice. Hint:\n",
    "Look back at Assignment 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=666)\n",
    "\n",
    "\n",
    "X = np.random.normal(0, 1, 100)\n",
    "\n",
    "eps = 0.1 * np.random.normal(0, 0.25, 100)\n",
    "\n",
    "ß0 = 20\n",
    "ß1 = 21\n",
    "ß2 = 22\n",
    "ß3 = 23\n",
    "\n",
    "y = ß0 + ß1*X + ß2*X*X + ß3*X*X*X + eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Using forward stepwise selection and also using backwards stepwise selection to choose the best model containing the predictors X, X2, ... X6. Comment on your results.\n",
    "\n",
    "### First we get the predictors X, X2, ... X6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>X^2</th>\n",
       "      <th>X^3</th>\n",
       "      <th>X^4</th>\n",
       "      <th>X^5</th>\n",
       "      <th>X^6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.824188</td>\n",
       "      <td>0.679286</td>\n",
       "      <td>0.559859</td>\n",
       "      <td>0.461429</td>\n",
       "      <td>0.380305</td>\n",
       "      <td>0.313443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.479966</td>\n",
       "      <td>0.230367</td>\n",
       "      <td>0.110569</td>\n",
       "      <td>0.053069</td>\n",
       "      <td>0.025471</td>\n",
       "      <td>0.012225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.173468</td>\n",
       "      <td>1.377027</td>\n",
       "      <td>1.615897</td>\n",
       "      <td>1.896204</td>\n",
       "      <td>2.225135</td>\n",
       "      <td>2.611124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.909048</td>\n",
       "      <td>0.826368</td>\n",
       "      <td>0.751209</td>\n",
       "      <td>0.682885</td>\n",
       "      <td>0.620775</td>\n",
       "      <td>0.564314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.571721</td>\n",
       "      <td>0.326865</td>\n",
       "      <td>-0.186876</td>\n",
       "      <td>0.106841</td>\n",
       "      <td>-0.061083</td>\n",
       "      <td>0.034923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X       X^2       X^3       X^4       X^5       X^6\n",
       "0  0.824188  0.679286  0.559859  0.461429  0.380305  0.313443\n",
       "1  0.479966  0.230367  0.110569  0.053069  0.025471  0.012225\n",
       "2  1.173468  1.377027  1.615897  1.896204  2.225135  2.611124\n",
       "3  0.909048  0.826368  0.751209  0.682885  0.620775  0.564314\n",
       "4 -0.571721  0.326865 -0.186876  0.106841 -0.061083  0.034923"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "X2 = X*X\n",
    "X3 = X*X*X\n",
    "X4 = X2*X2\n",
    "X5 = X2*X3\n",
    "X6 = X3*X3\n",
    "\n",
    "X_1to6 = pd.concat([X, X2, X3, X4, X5, X6], axis=1)\n",
    "X_1to6.columns = [\"X\", \"X^2\", \"X^3\", \"X^4\", \"X^5\", \"X^6\"]\n",
    "X_1to6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using forward stepwise selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'feature_idx': (2,),\n",
       "  'cv_scores': array([0.93488272]),\n",
       "  'avg_score': 0.9348827179222889,\n",
       "  'feature_names': ('X^3',)},\n",
       " 2: {'feature_idx': (1, 2),\n",
       "  'cv_scores': array([0.99037122]),\n",
       "  'avg_score': 0.9903712230101999,\n",
       "  'feature_names': ('X^2', 'X^3')},\n",
       " 3: {'feature_idx': (0, 1, 2),\n",
       "  'cv_scores': array([0.99999997]),\n",
       "  'avg_score': 0.9999999677441613,\n",
       "  'feature_names': ('X', 'X^2', 'X^3')},\n",
       " 4: {'feature_idx': (0, 1, 2, 4),\n",
       "  'cv_scores': array([0.99999997]),\n",
       "  'avg_score': 0.9999999681439081,\n",
       "  'feature_names': ('X', 'X^2', 'X^3', 'X^5')},\n",
       " 5: {'feature_idx': (0, 1, 2, 4, 5),\n",
       "  'cv_scores': array([0.99999997]),\n",
       "  'avg_score': 0.9999999682392479,\n",
       "  'feature_names': ('X', 'X^2', 'X^3', 'X^5', 'X^6')},\n",
       " 6: {'feature_idx': (0, 1, 2, 3, 4, 5),\n",
       "  'cv_scores': array([0.99999997]),\n",
       "  'avg_score': 0.9999999687670095,\n",
       "  'feature_names': ('X', 'X^2', 'X^3', 'X^4', 'X^5', 'X^6')}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "# Set forward=True, we get Step Forward Selection\n",
    "sfs = SFS(lr_model, \n",
    "           k_features=6, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           scoring='r2',\n",
    "           cv=0,\n",
    "           n_jobs=-1).fit(X_1to6, y)\n",
    "\n",
    "\n",
    "sfs.subsets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using backwards stepwise selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: {'feature_idx': (0, 1, 2, 3, 4, 5),\n",
       "  'cv_scores': array([0.99999997]),\n",
       "  'avg_score': 0.9999999687670095,\n",
       "  'feature_names': ('0', '1', '2', '3', '4', '5')},\n",
       " 5: {'feature_idx': (0, 1, 2, 3, 5),\n",
       "  'cv_scores': array([0.99999997]),\n",
       "  'avg_score': 0.9999999685256091,\n",
       "  'feature_names': ('0', '1', '2', '3', '5')},\n",
       " 4: {'feature_idx': (0, 1, 2, 5),\n",
       "  'cv_scores': array([0.99999997]),\n",
       "  'avg_score': 0.9999999679419835,\n",
       "  'feature_names': ('0', '1', '2', '5')},\n",
       " 3: {'feature_idx': (0, 1, 2),\n",
       "  'cv_scores': array([0.99999997]),\n",
       "  'avg_score': 0.9999999677441613,\n",
       "  'feature_names': ('0', '1', '2')},\n",
       " 2: {'feature_idx': (1, 2),\n",
       "  'cv_scores': array([0.99037122]),\n",
       "  'avg_score': 0.9903712230101999,\n",
       "  'feature_names': ('1', '2')},\n",
       " 1: {'feature_idx': (2,),\n",
       "  'cv_scores': array([0.93488272]),\n",
       "  'avg_score': 0.9348827179222889,\n",
       "  'feature_names': ('2',)}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set forward=False, we get Step Backward Selection\n",
    "lr_model2 = LinearRegression()\n",
    "sbs = SFS(lr_model2, \n",
    "           k_features=1, \n",
    "           forward=False, \n",
    "           floating=False, \n",
    "           scoring='r2',\n",
    "           cv=0,\n",
    "           n_jobs=-1).fit(X_1to6.values, y)\n",
    "\n",
    "sbs.subsets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color=\"red\">\n",
    "On the one hand, we find feature (2,), (1, 2), (0, 1, 2), (0, 1, 2, 4), (0, 1, 2, 4, 5) and (0, 1, 2, 3, 4, 5) using forward stepwise selection.\n",
    "    <br><br>On the other hand, we find feature (0, 1, 2, 3, 4, 5), (0, 1, 2, 3, 5)，(0, 1, 2, 5), (0, 1, 2), (1, 2) and (2,) using backward stepwise selection.\n",
    "    <br><br>As we can see from the results, the subsets are different when k equals to 4 and 5 (we select 4 or 5 features as the subset). We have the same 6 features since we only have 6 features in our dataset. But when k equals to 1, 2, 3, the two methods give the same result.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Now fit a lasso model to the simulated data, again using X, X2, ... X6 as predictors. Use cross-validation to select the optimal value of λ. Create plots of the cross-validation error as a function of λ. Report the resulting coefficient estimates and discuss the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ_list = list(np.arange(1e-06, 3, 1e-03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_score = 0\n",
    "best_λ = 0\n",
    "cv_scores = []\n",
    "for λ in λ_list:    \n",
    "    lasso_model = Lasso(alpha=λ, max_iter = 100000)\n",
    "    cv_score = cross_val_score(lasso_model,X_1to6, y, cv=5).mean()\n",
    "    cv_scores.append(cv_score)\n",
    "    if best_score < cv_score:\n",
    "        best_score = cv_score\n",
    "        best_λ = λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cross validation score')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(λ_list, cv_scores)\n",
    "plt.xlabel(\"λ\")\n",
    "plt.ylabel(\"cross validation score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we test 3000 λ in total.\n",
      "best cv score is  0.9999667230827649\n",
      "current λ is  0.014001\n"
     ]
    }
   ],
   "source": [
    "print(\"we test {} λ in total.\".format(len(λ_list)))\n",
    "print(\"best cv score is \", best_score)\n",
    "print(\"current λ is \", best_λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the intercept, AKA ß0:  19.901520821071063\n",
      "This is the coefficients:  [ 2.11102342e+01  2.24679721e+01  2.29006684e+01 -2.27382154e-01\n",
      "  4.54017458e-03  1.72669876e-02]\n"
     ]
    }
   ],
   "source": [
    "best_lasso_model = Lasso(alpha=best_λ).fit(X_1to6, y)\n",
    "print(\"This is the intercept, AKA ß0: \", best_lasso_model.intercept_)\n",
    "print(\"This is the coefficients: \", best_lasso_model.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color=\"red\">\n",
    "    The resulting coefficient estimates are ß0 =  19.90, ß1 = 21.11, ß2 = 22.47, ß3 = 22.90, ß4 = -0.23, ß5 = 0.0045, ß6 = 0.017.\n",
    "    The ß0, ß1, ß2, ß3 are very close to my simulation setting. If we round the results to integers, they are exactly the same coefficients as my presetting. And the ß4, ß5 and ß6 are fairly small numbers compared to the ß0, ß1, ß2, ß3.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "#### Read slides 20-32 and summarize them and add the summary at the end of assignment 4.\n",
    "\n",
    "<font size=2.5 color=\"red\">\n",
    "    We need approaches to estimate test error in order to choose the optimal model, because RSS and $R^2$ are only related to the training error. We can either directly estimate the test error (using a validation set approach or cross-validation approach) or indirectly estimate the test eorror by making an adjustment to the training error to account for the bias due to overfitting.\n",
    "    <br><br>Directly estimate: We can compute the validation set error or cross-validation error for each model under consideration, and then select the model for which the resulting estimated test error is smallest.\n",
    "    <br><br>Indirectly estimate: We can also use $C_p$, AIC, BIC and Adjusted $R^2$. The $C_p$ statistic adds a penalty to the training RSS to adjust for the fact that the training error tends to underestimate the test error. The AIC criterion is defined for a large class of models fit by maximum likelihood. And the BIC criterion is derived from a Bayesian point of view, but ends up looking similar to $C_p$ and AIC as well. Moreover, the adjusted $R^2$ statistic pays a price for the inclusion of unnecessary variables in the model. As a consequence, we choose <b>lower</b> $C_p$ statistic, AIC, BIC values and <b>bigger</b> adjusted $R^2$ value. \n",
    "    \n",
    "    \n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
